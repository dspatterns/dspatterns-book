# Batch creation of tables and plots

```{r setup, include=FALSE, echo=FALSE}
library(intendo)
library(pointblank)
library(gt)
library(dplyr)
library(tidyr)
library(glue)
```

- Good dataset: intendo
- Creating a function to make a table with different variables / filtered by values (using curly curly)
- See programming with dplyr: https://dplyr.tidyverse.org/articles/programming.html#how-tos-1
- Want to do something repetitively 
- Creating a function to make a plot (time series great example)
- Intro functions like `add_house_style()`
- R Markdown video for good looping pattern within doc for batch creation: https://www.youtube.com/watch?v=WkF7nqEYF1E


## This Chapter's Pattern

We want to take changing data (and changing requirements) and dependably make great looking tables and plots that might be part of a larger data sharing workflow. 

## Explore

Get some data from the intendo package

```{r}
all_revenue <- intendo::all_revenue()
```

Use **pointblank**'s table transform functions to get slices of that `all_revenue` table.

```{r}
#| label: slice-all-revenue
#| paged.print: false

initial_date <- "2015-01-10"
ending_date  <- "2015-01-15"
end_m1_date  <- "2015-01-14"

all_rev_jan_segment <- 
  all_revenue |>
  tt_time_slice(
    time_column = "session_start",
    slice_point = ending_date,
    keep = "left"
  ) |>
  tt_time_slice(
    time_column = "session_start",
    slice_point = initial_date,
    keep = "right"
  )
  
all_rev_jan_segment
```

A quick check for whether the slicing worked is to use **gt**'s `gt_preview()`, which provides the first five rows and the last row in a small table:

```{r}
#| label: all-revenue-gt-preview

gt_preview(all_rev_jan_segment)
```

This looks good as we can see early morning values on `"2015-01-10"` and near-midnight values on `"2015-01-15"` (in the `session_start` column). We might want to do a few more data validation checks, just to be sure what we're starting with is of high enough quality. We'll use **pointblank** for that and introduce the `all_rev_jan_segment` to these three basic data quality checks:

1. Do all rows have `session_start` values within the expected time range?
2. Are all rows distinct from each other?
3. Are all rows complete (i.e., having no missing values anywhere)?

```{r}
#| label: check-slice-all-revenue
#| paged.print: false

all_rev_jan_segment |>
  col_vals_between(
    columns = session_start,
    left = lubridate::ymd_hms("2015-01-10 00:00:00"),
    right = lubridate::ymd_hms("2015-01-15 11:59:59")
  ) |>
  rows_complete() |>
  rows_distinct()
```

Because the table was returned with no errors reported, all of the data validation checks passed with flying colors! There are of course many more data checks that could potentially be performed but even just a few basic checks are valuable and we could move forward, feeling a bit more confident about the input data.

Let's generate a summary of the top-five selling items in each day of this abbreviated dataset using functions from **dplyr**.

```{r}
#| label: get-basic-summary
#| paged.print: false

daily_revenue_top5 <-
  all_rev_jan_segment |>
  filter(item_type == "iap") |>
  mutate(date = as.Date(time)) |>
  group_by(date, item_name) |>
  summarize(
    revenue = sum(item_revenue),
    .groups = "drop"
  ) |>
  arrange(desc(date), desc(revenue)) |>
  group_by(date) |>
  filter(row_number() %in% 1:5) |>
  mutate(rank = 1:5) |>
  ungroup()

daily_revenue_top5
```

Making a **gt** table from this summary makes for a very presentable deliverable.

```{r}
#| label: daily-revenue-top5-gt-table

daily_revenue_top5 |>
  gt(rowname_col = "item_name", groupname_col = "date") |>
  fmt_currency(columns = revenue) |>
  cols_width(everything() ~ px(200)) |>
  fmt_roman(column = rank) |>
  cols_merge(columns = c(item_name, rank), pattern = "{2}. {1}") |>
  tab_header(
    title = "Daily Top Five IAPs",
    subtitle = md(glue("Data from `{initial_date}` to `{end_m1_date}`."))
  ) |>
  tab_options(column_labels.hidden = TRUE) |>
  opt_all_caps() |>
  opt_vertical_padding(scale = 0.5) |>
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_row_groups()
  )
```

This looks pretty nice. And things are set up for even more flexibility. I mean, you might get asked for all sorts modifications of this summary table. Some examples:

1. Give me the top 10 items per day, going back 4 days from today
2. I'd like to see the best performing ad types
4. This would be much better with the company colors applied somewhere

To make this all possible we can generate a function. The ultimate function for getting a table of revenue figures really. 

## Understand

We have three basic components to making that reporting table:

1. Data acquisition
2. Data transformation and summarization
3. Data tabulation for presentation

If we are to make a single, dependable function, it would be acceptable (and easier for you) to get all these components into that function. Let's start with a name and call this function `get_sales_tbl()`.

Now let's think of what's needed in terms of options. We know we should allow for some variation and flexibilty. We don't want *too much* of that because it could result in a lot of code that could get brittle and harder to maintain. The art in this sort of thing is finding a middle ground and extended later as necessity warrants. Let's start by popping in all the R code we used before into this function, with zero options:

```{r}
#| label: daily-revenue-top5-first-function

get_sales_tbl <- function() {
  
  initial_date <- "2015-01-10"
  ending_date  <- "2015-01-15"
  end_m1_date  <- "2015-01-14"

  all_rev_jan_segment <- 
    all_revenue |>
    tt_time_slice(
      time_column = "session_start",
      slice_point = ending_date,
      keep = "left"
    ) |>
    tt_time_slice(
      time_column = "session_start",
      slice_point = initial_date,
      keep = "right"
    )
  
  daily_revenue_top5 <-
    all_rev_jan_segment |>
    filter(item_type == "iap") |>
    mutate(date = as.Date(time)) |>
    group_by(date, item_name) |>
    summarize(
      revenue = sum(item_revenue),
      .groups = "drop"
    ) |>
    arrange(desc(date), desc(revenue)) |>
    group_by(date) |>
    filter(row_number() %in% 1:5) |>
    mutate(rank = 1:5) |>
    ungroup()
  
  daily_revenue_top5 |>
    gt(rowname_col = "item_name", groupname_col = "date") |>
    fmt_currency(columns = revenue) |>
    cols_width(everything() ~ px(200)) |>
    fmt_roman(column = rank) |>
    cols_merge(columns = c(item_name, rank), pattern = "{2}. {1}") |>
    tab_header(
      title = "Daily Top Five IAPs",
      subtitle = md(glue("Data from `{initial_date}` to `{end_m1_date}`."))
    ) |>
    tab_options(column_labels.hidden = TRUE) |>
    opt_all_caps() |>
    opt_vertical_padding(scale = 0.5) |>
    tab_style(
      style = cell_text(align = "center"),
      locations = cells_row_groups()
    )
}
```

What was made was a function that's not too functional. It has no arguments (y'know, options). It'll give you the same table every single time. Obviously, not what anyone wants but it's a good starting point because everything is here. We just need to make this usable for the real-world now. 

In terms of design constraints, let's make it this is always some sort of daily ranking of something from the source table. In terms of options, we want these three:

1. A way to modify the date range
2. Option to modify the number of items in the ranking.
3. Two styling options: basic and company-themed

Let's put that into the function's *signature*, along with some defaults:

```r
get_sales_tbl <- function(
    data,
    final_day = lubridate::today() - lubridate::days(2),
    start_day = lubridate::today() - lubridate::days(6),
    days_back = NULL,
    n = 5,
    styling = c("basic", "company")
) {

...

}
```

The `data` argument is the dataset. This is the data frame or tibble that first gets processed by the **dplyr** code. The pairing of `final_day` and `start_day` allow for input of dates. The defaults make it so that the system's clock time is involved, getting a start day and a final day two days back from the present day. As an additional option, the `start_day` input could be overridden by providing a `days_back` number (good if you don't really want to do any calendar-based calculations for larger ranges of days). The `n` argument is for the number of ranked items to include in each day. Finally, `styling` allows for choosing a theme for the **gt**-based table output.

The new function, after incorporation of the options, might look something like this:

```{r}
#| label: daily-revenue-revised-function

get_sales_tbl <- function(
    data,
    final_day = lubridate::today() - lubridate::days(2),
    start_day = lubridate::today() - lubridate::days(6),
    days_back = NULL,
    n = 5,
    styling = c("company", "basic")
) {
  
  styling <- match.arg(styling)

  final_day <- as.Date(final_day)
  
  if (!is.null(days_back) && is.numeric(days_back)) {
    start_day <- final_day - lubridate::days(days_back)
  } else {
    start_day <- as.Date(start_day)
  }
  
  days <- seq(start_day, final_day, by = "days")

  filtered_data <- 
    data |>
    dplyr::mutate(sale_day = as.Date(time)) |>
    dplyr::filter(sale_day %in% days)
  
  .top_n_sequence <- seq(1, n)
  
  daily_revenue_ranked <-
    filtered_data |>
    filter(item_type == "iap") |>
    mutate(date = as.Date(time)) |>
    group_by(date, item_name) |>
    summarize(
      revenue = sum(item_revenue),
      .groups = "drop"
    ) |>
    arrange(desc(date), desc(revenue)) |>
    group_by(date) |>
    filter(row_number() %in% .top_n_sequence) |>
    mutate(rank = .top_n_sequence) |>
    ungroup()
  
  output_tbl <-
    daily_revenue_ranked |>
    gt(rowname_col = "item_name", groupname_col = "date") |>
    fmt_currency(columns = revenue) |>
    cols_width(everything() ~ px(200)) |>
    fmt_roman(column = rank) |>
    cols_merge(columns = c(item_name, rank), pattern = "{2}. {1}") |>
    tab_header(
      title = "Daily Top Sales Items",
      subtitle = md(glue("Data from `{start_day}` to `{final_day}`."))
    ) |>
    tab_options(column_labels.hidden = TRUE) |>
    opt_all_caps() |>
    opt_vertical_padding(scale = 0.5) |>
    tab_style(
      style = cell_text(align = "center"),
      locations = cells_row_groups()
    )
  
  if (styling == "company") {
    
    output_tbl <-
      output_tbl |>
      tab_options(
        table.background.color = adjust_luminance("beige", steps = 1.5),
        table.border.bottom.width = px(3),
        table.border.top.width = px(3),
        table.border.bottom.color = "black",
        table.border.top.color = "black",
        row_group.background.color = "gray98",
        source_notes.background.color = "darkorange"
      ) |>
      tab_style(
        style = cell_fill(color = "palegreen"),
        locations = cells_body(columns = revenue)
      ) |>
      tab_source_note(
        source_note = md("**NOTE:** This document is for internal use only and should not to be distributed to external parties.") 
      )
  }
  
  output_tbl
}
```

This shiny new function is now flexible and it really works! Always test your custom-built functions with a lot of sensible input combinations. The more important the function is, the more robust and well-tested it should become. If we use `get_sales_tbl()` with the dataset above and the `final_day = "2015-06-30"` and `days_back = 2` options, we do get a nice-looking table:

```{r}
#| label: daily-revenue-revised-function-invoke

get_sales_tbl(
  all_revenue,
  final_day = "2015-06-30",
  days_back = 2
)
```

However, if we use the default options (i.e., by invoking `get_sales_tbl(all_revenue)`) we get an error. Turns out the dataset obtained from using `intendo::all_revenue()` only contains data from 2015. So, the defaults are optimized for data that continuously updating to the present day. This is great in practice for that common scenario but not so good with a historical data extract like we have here.

## Explain

## Share

## DIY

- dataset: ``


# Batch creation of tables and plots

```{r setup, include=FALSE, echo=FALSE}
library(intendo)
library(pointblank)
library(gt)
library(dplyr)
library(tidyr)
library(glue)
```

- Good dataset: intendo
- Creating a function to make a table with different variables / filtered by values (using curly curly)
- See programming with dplyr: https://dplyr.tidyverse.org/articles/programming.html#how-tos-1
- Want to do something repetitively 
- Creating a function to make a plot (time series great example)
- Intro functions like `add_house_style()`
- R Markdown video for good looping pattern within doc for batch creation: https://www.youtube.com/watch?v=WkF7nqEYF1E


## This Chapter's Pattern

We want to take changing data (and changing requirements) and dependably make great looking tables and plots that might be part of a larger data sharing workflow. 

## Explore

Get some data from the intendo package

```{r}
all_revenue <- intendo::all_revenue()
```

Use **pointblank**'s table transform functions to get slices of that `all_revenue` table.

```{r}
#| label: slice-all-revenue
#| paged.print: false

initial_date <- "2015-01-10"
ending_date  <- "2015-01-15"
end_m1_date  <- "2015-01-14"

all_rev_jan_segment <- 
  all_revenue |>
  tt_time_slice(
    time_column = "session_start",
    slice_point = ending_date,
    keep = "left"
  ) |>
  tt_time_slice(
    time_column = "session_start",
    slice_point = initial_date,
    keep = "right"
  )
  
all_rev_jan_segment
```

A quick check for whether the slicing worked is to use **gt**'s `gt_preview()`, which provides the first five rows and the last row in a small table:

```{r}
#| label: all-revenue-gt-preview

gt_preview(all_rev_jan_segment)
```

This looks good as we can see early morning values on `"2015-01-10"` and near-midnight values on `"2015-01-15"` (in the `session_start` column). We might want to do a few more data validation checks, just to be sure what we're starting with is of high enough quality. We'll use **pointblank** for that and introduce the `all_rev_jan_segment` to these three basic data quality checks:

1. Do all rows have `session_start` values within the expected time range?
2. Are all rows distinct from each other?
3. Are all rows complete (i.e., having no missing values anywhere)?

```{r}
#| label: check-slice-all-revenue
#| paged.print: false

all_rev_jan_segment |>
  col_vals_between(
    columns = session_start,
    left = lubridate::ymd_hms("2015-01-10 00:00:00"),
    right = lubridate::ymd_hms("2015-01-15 11:59:59")
  ) |>
  rows_complete() |>
  rows_distinct()
```

Because the table was returned with no errors reported, all of the data validation checks passed with flying colors! There are of course many more data checks that could potentially be performed but even just a few basic checks are valuable and we could move forward, feeling a bit more confident about the input data.

Let's generate a summary of the top-five selling items in each day of this abbreviated dataset using functions from **dplyr**.

```{r}
#| label: get-basic-summary
#| paged.print: false

daily_revenue_top5 <-
  all_rev_jan_segment |>
  filter(item_type == "iap") |>
  mutate(date = as.Date(time)) |>
  group_by(date, item_name) |>
  summarize(
    revenue = sum(item_revenue),
    .groups = "drop"
  ) |>
  arrange(desc(date), desc(revenue)) |>
  group_by(date) |>
  filter(row_number() %in% 1:5) |>
  mutate(rank = 1:5) %>%
  ungroup()

daily_revenue_top5
```

Making a **gt** table from this summary makes for a very presentable deliverable.

```{r}
#| label: daily-revenue-top5-gt-table

daily_revenue_top5 |>
  gt(rowname_col = "item_name", groupname_col = "date") |>
  fmt_currency(columns = revenue) |>
  cols_width(everything() ~ px(200)) |>
  fmt_roman(column = rank) |>
  cols_merge(columns = c(item_name, rank), pattern = "{2}. {1}") |>
  tab_header(
    title = "Daily Top Five IAPs",
    subtitle = md(glue("Data from `{initial_date}` to `{end_m1_date}`."))
  ) |>
  tab_options(column_labels.hidden = TRUE) |>
  opt_all_caps() |>
  opt_vertical_padding(scale = 0.5) |>
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_row_groups()
  )
```

This looks pretty nice. And things are set up for even more flexibility. I mean, you might get asked for all sorts modifications of this summary table. Some examples:

1. Give me the top 10 items per day, going back 4 days from today
2. I'd like to see the best performing ad types
4. This would be much better with the company colors applied somewhere

To make this all possible we can generate a function. The ultimate function for getting a table of revenue figures really. 

## Understand

We have three basic components to making that reporting table:

1. Data acquisition
2. Data transformation and summarization
3. Data tabulation for presentation

If we are to make a single, dependable function, it would be acceptable (and easier for you) to get all these components into that function. Let's start with a name and call this function `get_sales_tbl()`.

Now let's think of what's needed in terms of options. We know we should allow for some variation and flexibilty. We don't want *too much* of that because it could result in a lot of code that could get brittle and harder to maintain. The art in this sort of thing is finding a middle ground and extended later as necessity warrants. Let's start by popping in all the R code we used before into this function, with zero options:

```{r}
#| label: daily-revenue-top5-first-function

get_sales_tbl <- function() {
  
  initial_date <- "2015-01-10"
  ending_date  <- "2015-01-15"
  end_m1_date  <- "2015-01-14"

  all_rev_jan_segment <- 
    all_revenue |>
    tt_time_slice(
      time_column = "session_start",
      slice_point = ending_date,
      keep = "left"
    ) |>
    tt_time_slice(
      time_column = "session_start",
      slice_point = initial_date,
      keep = "right"
    )
  
  daily_revenue_top5 <-
    all_rev_jan_segment |>
    filter(item_type == "iap") |>
    mutate(date = as.Date(time)) |>
    group_by(date, item_name) |>
    summarize(
      revenue = sum(item_revenue),
      .groups = "drop"
    ) |>
    arrange(desc(date), desc(revenue)) |>
    group_by(date) |>
    filter(row_number() %in% 1:5) |>
    mutate(rank = 1:5) %>%
    ungroup()
  
  daily_revenue_top5 |>
  gt(rowname_col = "item_name", groupname_col = "date") |>
  fmt_currency(columns = revenue) |>
  cols_width(everything() ~ px(200)) |>
  fmt_roman(column = rank) |>
  cols_merge(columns = c(item_name, rank), pattern = "{2}. {1}") |>
  tab_header(
    title = "Daily Top Five IAPs",
    subtitle = md(glue("Data from `{initial_date}` to `{end_m1_date}`."))
  ) |>
  tab_options(column_labels.hidden = TRUE) |>
  opt_all_caps() |>
  opt_vertical_padding(scale = 0.5) |>
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_row_groups()
  )
}
```

What was made was a function that's not too functional. It has no arguments (y'know, options). It'll give you the same table every single time. Obviously, not what anyone wants but it's a good starting point because everything is here. We just need to make this usable for the real-world now. 

In terms of design constraints, let's make it this is always some sort of daily ranking of something from the source table. In terms of options, we want these three:

1. A way to modify the date range
2. Option to modify the number of items in the ranking.
3. Two styling options: basic and company-themed


## Explain

## Share

## DIY

- dataset: ``


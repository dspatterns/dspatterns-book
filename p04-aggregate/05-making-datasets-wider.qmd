# Making Datasets Wider

{{< include ../_patterns.qmd >}}

```{r setup, include=FALSE, echo=FALSE}
library(dspatterns)
library(dplyr)
library(tidyr)
library(gt)
library(bakeoff)
library(palmerpenguins)
library(janitor)
```

Wide data... why do you want it? It is **awesome** for summary tables. Display tables just present and look better when they have a bit of width to them. Long data, that's great for plotting, no question, but we won't do any of that in this chapter. This chapter is dedicated to summary tables and all of their charms.

Here's the collection of packages needed for this chapter:

- **tidyverse**: for the use of the **dplyr** and **tidyr** packages
- **gt**: for its datasets and table-making capabilities
- **bakeoff**: for the `ratings` dataset
- **palmerpenguins**: for the `penguins` dataset
- **janitor**: for cleaning column names

## Explore

Let's get a little practice in make wide tables from long tables. The **bakeoff** package's `ratings` dataset is really interesting as it contains a wealth of information concerning viewership for every episode across the ten series. Let's have a look at that dataset once again by printing the tibble.

```{r, paged.print=FALSE}
ratings
```

Let's make it so that we get the following wide-table structure:

- Each row represents a series (from `1` to `10`)
- The 7-day viewership data (in millions of viewers) will appear in columns for each episode in a season
- all other data (like airdate, rankings, etc.) will be omitted

We start by keeping only the data columns we need. In this case, that's the `series`, `episode`, and `viewers_7day` columns (and we do this with **dplyr**'s `select()` function). Then, it's a matter of using `pivot_wider()` with the `names_from` and `values_from` arguments.

```{r, paged.print=FALSE}
ratings_by_series <-
  ratings |>
  select(series, episode, viewers_7day) |>
  pivot_wider(names_from = episode, values_from = viewers_7day)

ratings_by_series
```

It might be weird to have column names that are numbers. If you think it is strange and rather have more text-y column names, then we can use the `names_prefix` argument to change all that. In this alternate bit of code, we do pretty much the same operations as before, except that `names_prefix = "episode_"` is employed to prefix each new column name with `episode_`.

```{r, paged.print=FALSE}
ratings_by_series_alt <-
  ratings |>
  select(series, episode, viewers_7day) |>
  pivot_wider(
    names_from = episode,
    values_from = viewers_7day,
    names_prefix = "episode_"
  )

ratings_by_series_alt
```

The orginal dataset has viewership numbers represented in millions. So a value like `3.85` really means 3,850,000. If you wanted to expand these values to real number values you could mutate all of the columns with **dplyr**, where each column is multiplied by `1e6` (1 million). Or, you could do it in the `pivot_wider()` statement! With the `values_fn` argument, you could pass in a function that takes `x` (any input value) and returns a variation of that. We'll use `function(x) x * 1e6` for `values_fn` and what we'll get is a wide table with all of the viewership numbers in the millions (i.e., big numbers).

```{r, paged.print=FALSE}
ratings_by_series_num_expand <-
  ratings |>
  select(series, episode, viewers_7day) |>
  pivot_wider(
    names_from = episode,
    values_from = viewers_7day,
    values_fn = function(x) x * 1e6
  )

ratings_by_series_num_expand
```
If we wanted to incorporate the air date along with the viewership figures, two columns could be specified in the `values_from` argument. We can no longer use the `values_fn` with a supplied function because we're getting both `numeric` and `Date` columns this time around (and the function would try to multiply dates by one million). The new-column naming will mash together a `values_from` column name (either `viewers_7day` or `uk_airdate`) with the values from the `episode` column. We can have it so that some text gets inserted in between these text fragments, and we'll do that with the `names_sep` argument. 

```{r, paged.print=FALSE}
ratings_by_series_with_air_date <-
  ratings |>
  select(series, episode, viewers_7day, uk_airdate) |>
  pivot_wider(
    names_from = episode,
    names_sep = "_episode_",
    values_from = c(viewers_7day, uk_airdate)
  ) |>
  mutate(across(starts_with("viewers_7day"), function(x) x * 1e6))

ratings_by_series_with_air_date
```

This makes for a pretty wide table (21 columns!) but only 10 rows. We basically got what we asked for. Because we can't use `values_fn` to multiply the `viewers_7day_*` columns by `1e6` the alternative is to use **dplyr**'s `mutate()` with the `across()` helper function (to target the right columns for the multiplying function). Though that last incantation is somewhat difficult to remember how to use, we *did* get it done here.

## Understand

You'll sometimes run into the case where you have a lot of columns in your dataset that you want to widen. But many of those columns will be extraneous, in that you don't want them in the pivoted table. We solved for this in our first example with `pivot_wider()` by using an initial `select()` statement. Here it is again:

```{r, paged.print=FALSE}
ratings_by_series <-
  ratings |>
  select(series, episode, viewers_7day) |>
  pivot_wider(names_from = episode, values_from = viewers_7day)

ratings_by_series
```

However, we could take advantage of `id_cols` and state which of the columns makes for an 'ID' for a row. Put another way, the combined information from the columns will uniquely identify each column. Anything not in `id_cols` will be dropped in the pivoted table. Here's a variation of the earlier example that uses `id_cols` in `pivot_wider()` and drops the `select()` statement.

```{r, paged.print=FALSE}
ratings_by_series_id_cols <-
  ratings |>
  pivot_wider(
    id_cols = series,
    names_from = episode,
    values_from = viewers_7day
  )

ratings_by_series_id_cols
```

It gives us the same output table. Which is great to see. Importantly, any columns provided to `id_cols` must not be given to either of the `names_from` or `values_from` arguments. The above example used only one column in `id_cols` but conceivably you could have a few columns that, only in combination, concretely and uniquely describe the row (a good example is a first name, a last name, and an address). 

A very pro move to use with `pivot_wider()` is to combine it with `group_by()`/`summarize()`. The summarizing part could happen before pivoting and here's an example where the summarizing of the `penguins` dataset happens right before the pivoting operation.

```{r, paged.print=FALSE}
penguins_average_mass_by_year <-
  penguins |>
  group_by(island, year) |>
  summarize(
    mean_body_mass_g = mean(body_mass_g, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    id_cols = island,
    names_from = year, 
    values_from = mean_body_mass_g
  )

penguins_average_mass_by_year
```

Here's a slightly different pivoting-after-summarizing example. Where we transpose the columns provided to the `id_cols` and `names_from` arguments. This gives us the three different years as rows and the different islands as columns.

```{r, paged.print=FALSE}
penguins_average_mass_by_island <-
  penguins |>
  group_by(island, year) |>
  summarize(
    mean_body_mass_g = mean(body_mass_g, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    id_cols = year,
    names_from = island, 
    values_from = mean_body_mass_g
  )

penguins_average_mass_by_island
```

With some practice, using `pivot_wider()` in combination with a summary of a dataset will become second nature. It's a very powerful pattern, as summarizing is undeniably useful (especially for making summary tables meant for publication) and pivoting that to a wide form of your choosing makes the summary more readable. 

## Explain

With the previous examples demonstrating a wide range of uses for `pivot_wider()`, we've really gotten to grips with how to effectively use that great function. There is a pattern, though, that may be encountered less commonly: converting a wide dataset to a *different* wide dataset. Put another way, the variables that represent the bulk of the table columns should be replaced with names from another column. While this sort of scenario is difficult to articulate, we can explain the problem and work through the solution with the examples that will follow.

The `illness` dataset in the **gt** package starts out as a wide type of dataset. Put another way it is not tidy and we can see that right away given there are multiple columns for different observations (e.g., `day_3`, `day_4`, etc.).

```{r, paged.print=FALSE}
illness
```

In the above form, we have the different tests performed on a patient as a different row. Now, the tests were performed every day (from day 3 to day 8) and the result of each type of test on each day is written in the cell that intersects these two different things. It's just tabulated in this way. But what if you wanted the different days of measurement to be enumerated in a column, having the different tests occupy a different column? There's a way to do that and it involves two steps: (1) pivoting to long data with `pivot_longer()`, and (2) pivoting to a wide form again with `pivot_wider()`.

Let's do this one step at a time. Starting, as stated earlier, with a `pivot_longer()` statement. To simplify things, we'll use only the `test` and the `day_*` columns.

```{r, paged.print=FALSE}
illness_redux <- 
  illness |>
  select(test, starts_with("day")) |>
  pivot_longer(
    cols = starts_with("day"),
    names_to = "day",
    names_prefix = "day_",
    values_to = "value"
  )

illness_redux
```

Now *this* is some tidy data. The columns we have now are: `test`, `day`, and `value`. And it's certainly a lot longer than the original table, with 273 rows (compared to the 39 in the original `illness` dataset). We had to specially handle the `day_*` column names. To turn them into values in the new `day` column, the `names_prefix = "day_"` option needed to be specified.

Because the data is tidy and long we can now make it wide, but in a different way. The `pivot_wider()` statement is relatively simple (just needing a column each for `names_from` and `values_from`). To clean up the new column names, we'll employ the `clean_names()` function from the **janitor** package.

```{r, paged.print=FALSE}
illness_redux <-
  illness_redux |>
  pivot_wider(
    names_from = test,
    values_from = value
  ) |>
  clean_names()

illness_redux
```

This is not just a wide table, it's *super* wide with 40 columns. Totally fine if using this data for further analysis but maybe not what you want if you're making a summary table for publication from the widened data. There are two things you can do to limit the amount of columns in the this wide output: (1) use the `select()` function to pick the columns to keep, or (2) `filter()` the `test` column in the data just before (or even just after) the `pivot_longer()` statement.

## Share

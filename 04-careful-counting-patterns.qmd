# Careful Counting Patterns

```{r setup, include=FALSE, echo=FALSE}
library(dspatterns)
library(bakeoff)
library(dplyr)
library(skimr)
library(gt)
```

```{css, echo=FALSE}
# TODO: place in external CSS file
pre code {
    overflow-wrap: unset;
    word-break: unset;
    white-space: unset;
}

pre.numberSource code > span > a:first-child::before {
  left: -0.5em;
}

pre.numberSource {
  margin-left: 2em;
}
```

## Introduction

Private Notes: 

- Use the bakeoff package (diamonds has been seen before)
  - user the bakers datasets
  - how many bakers...
  
## This chapter's pattern

Make treemap visual with R (squares in quadrant)

- Explore: glimpse / head / tail / skimr
- Understand: 
  - tables + viz (distinct / count / geom_col janitor::tabyl)
  - from exploratory plots (confirms or disproves your assumptions about the data) gain an intuition and develop that ability
- Explain: nrow/ncol + combine with glue for inline code? / epoxy
- Share (Collaborate/Communicate): use pointblank; gt for tables?
  
## Explore

We are going to explore a few datasets from the **bakeoff** package. It's primarily a *dataset* package but it has a few handy functions as well. Let's begin with **bakeoff**'s `bakers` dataset. We know nothing about it at this point so we'll use `glimpse()` to inspect the structure of the data table (plus some of row content).

```{r how-many-bakers-glimpse, attr.source='.numberLines'}
glimpse(bakers)
```

Right up front we get told there are 120 rows and 8 columns. That's very useful because we get a sense of the overall size of the dataset. Because `bakers` is a tibble, when the core Tidyverse packages are loaded with `library(tidyverse)` we get a pretty nice printing of the table just by calling its name. Check it out:

```{r}
bakers
```

There's no shortage of ways to preview a tabular dataset. We can even use the **gt** package (loaded with `library(gt)`) to give us an HTML-based preview of `bakers`. For that, we use the `gt_preview()` function. Here's how that looks:

```{r}
gt_preview(bakers)
```
<br />

This table presents really nicely and so it's great for sharing a preview of the dataset (e.g., in static R Markdown documents).

Sometimes, however, you need more. You need some stats. Descriptive statistics can better aid in the understanding of a dataset. You'll get a sense of numerical ranges (for numerical columns), if there are missing values in certain columns, and the degree of uniqueness across columns (or variables). There are multiple great solutions for this in R. One of them in the `skim()` function provided by the **skimr** package:

```{r}
skimr::skim(bakers)
```

By default, we get a lot of information very quickly. The printed info gives us:

- the table name and its dimensions (row and column counts)
- a listing of column types and their frequencies
- whether there are 'grouped' variables (via dplyr's `group_by()` function)
- info tables for variables by their type with the degree of missingness (`n_missing`) and the completion rate `complete_rate`; let's look at the specialized bits of info for the three column types we have in `bakers`:
  - *character*: minimum and maximum string lengths, 'empty' strings (`""`), number of unique strings (`n_unique`), and number of strings that are just whitespace (e.g., `" "`)
  - *factor*: is the factor `ordered`? How many unique factor levels are there? What are the most frequent levels?
  - *numeric*: descriptive stats like the mean, the standard deviation, quantiles, *and*, a nice little histogram for a quick visual of the data distribution 

The `skim()` function is certainly something to keep in your toolbelt, and quite handy when you get a new dataset to look at for the first time.

Another option is the `scan_data()` function from the **pointblank** package. It's a lot like `skim()` in principle, except it provides even more information and does so in an HTML-based report. Let's look at `bakers` via `scan_data()`

<!-- Graphic of scan_data() report here -->

The report is huge and highly interactive. The graphic above tries to distill what you'll find in the report. More description and a discussion on why one might use this and when it's appropriate to use. 

## Understand

Janitor functions: `janitor::tabyl()` + a few `adorn_*()` functions (just enough to get understanding)

But are the contestants unique across all the rows? (Did somebody drop out and come back?)

```{r}
bakers %>% distinct(baker_full)
```

- most common first name `baker_first`?

```{r}
bakers %>% distinct(baker_first)
```

`107` is less than the `120` row count we've seen earlier. Let's instead `count()` by first name (`baker_first`)

```{r}
bakers %>% count(baker_first)
```

This is more apparent when sorting with the `sort` option in `count()`.

```{r}
bakers %>% count(baker_first, sort = TRUE)
```

Now we see that the most common first name is `Kate`.

This is useful but a bit confusing because of the sorting (only descending by `name_total`).

```{r}
bakers %>% 
  distinct(series, baker_first) %>%
  add_count(baker_first, sort = TRUE, name = "name_total")
```

   - overall?

Let's do a count of baker by series (were there any series where two people shared the same name?)

```{r}
bakers %>% count(series, baker_first, sort = TRUE)
```

Seems like no? All `n` values are `1` and the total count here is the same as before (`120`). 

```{r}
bakers %>% count(series)
```

This follows the original order of the table (series increasing). Interestingly, the first series started with only 10 but it became at least bakers dozen's worth later on. 

```{r}
bakers_by_series <- bakers %>% count(series)
```

In R Markdown, we often want to use the things we calculated inside the text. We can do that with `r knitr::inline_expr("min(bakers_by_series$n)")`
 
    - per series?
    - per hometown?
    
EXERCISE: Can you figure out if any bakers are from the same hometown? How about from the same hometown and the same series?

```{r}
bakers %>% count(hometown, series, sort = TRUE)
```
    
    - per episode / per series?
    
```{r}
episodes %>% count(series, episode)
```

## Explain

Sometimes, in the text of a document, you might want to describe your data. We can, for example, use `nrow()` to get the number of rows in the table like this `r knitr::inline_expr(" nrow(bakers)")`.

This is similar: bakers %>% n_distinct()



- use inline code
- present with gt() - provide a few basics here

## Share

pointblank::scan_data()
pointblank::draft_validation_report()


- This chapter really ought to be an intro vis / data inspection/exploration section with multiple packages
- introduce functions:
  - dplyr::glimpse()
  - dplyr::distinct() (getting unique rows by selection of columns)
  - dplyr::count() (counting distinct values by rows; count by series, use built-in sort feature)
  - geom_boxplot()
- use some code from course material that uses bakeoff
  - links: https://alison.netlify.app/rls-plot-twist/#19, https://alison.netlify.app/rls-plot-twist/#19 (counting slides)
- start off with histogram and create this plot: https://alison.netlify.app/rls-plot-twist/#19
- histogram of ages of bakers + other interesting plots
- goals: making exploratory bar charts and histograms (useful for initial understanding of the data)



## Project Ideas

(should have a fully working set of Rmd templates, presented in the form of a project template - this can be prepped for the reader with a function call)

The moma dataset (https://apreshill.github.io/data-vis-labs-2018/02-moma.html) would be great for a project
- explore using the lisa palette from paletteer


### Packages Needed

 - installation details (script with `library()` calls)
 - possibly use: https://github.com/rstudio4edu/rmd4edu/blob/master/R/lesson.R


